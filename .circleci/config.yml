version: 2.1

jobs:
  pr-build-docs:
    docker:
      # The Fornax-Hea images can definitely be used here, just we're having some issues with what supporting files
      #  software are included at the moment, so it is easier to use a different image and just install HEASoft
      #  at the moment
      #  - image: ghcr.io/nasa-fornax/fornax-images/fornax-hea
      - image: ghcr.io/nasa-fornax/fornax-images/fornax-hea:stable
    # This sets the amount of compute that we'll use to run the on-PR builds/tests - this particular setup corresponds
    #  to 2 CPUs and 4GB of RAM as of 16th September 2025
    resource_class: medium
    # Setting up environment variables - for instance the version of the Chandra CalDB we want to use
    environment:
      CHANDRA_CALDB_VER: 4.12.2
      CIRCLECI_XMM_CCF_VER: 1

    # What this job is actually going to do!
    steps:
      - attach_workspace:
          at: ~/

      # Checking out the branch we're interested in
      - checkout

      # 1. Load the most recent cache that matches the stub of the MyST notebook cache key
      # 2. Restore the XMM calibration file cache, saves us downloading it every time!
      # 3. And the same thing with the Chandra CalDB cache
      - restore_cache:
          keys:
            - jupyter_ch-{{ .Branch }}-
            - xmm-ccf-cs
            - ciao-caldb-cs

      # Some missions (e.g. XMM, Chandra, eROSITA) require that their calibration files are available locally. We
      #  don't want to download them every single time, so we're going to cache them for future runs.
      # TODO This might need changing, rsync would keep the files updating, but the question is how I then tell
      #  when the files have changed, and thus need to update the cache (or rather make a new version of the cache).
      - run:
          name: Acquiring/validating XMM-CCFs
          command: |
            # If we can't see the xmm_ccf directory, or the version file we generate doesn't contain the same
            #  version number as currently defined in the environment variable, we have to download the data
            if [ ! -d xmm-ccf ] || [[ ! "$(<"xmm-ccf/xmm-ccf.ver")" == "$CIRCLECI_XMM_CCF_VER" ]]; then
              # Makes the xmm-ccf directory, if it doesn't already exist. This is a different approach to the
              #  what we do for the Chandra CalDB below, as rsync will update files if there are newer versions
              #  available, so we don't want to delete the directory.
              mkdir -p xmm-ccf
              # We do delete the version file, if it exists, as if we get to this point then we are either downloading
              #  the data for the first time, or the version number has changed.
              [ -f xmm-ccf/xmm-ccf.ver ] && rm xmm-ccf/xmm-ccf.ver

              # Make a new version file
              echo "${CIRCLECI_XMM_CCF_VER}" > xmm-ccf/xmm-ccf.ver

              # Actually rsync the calibration files
              rsync -v -a --delete --delete-after --force --include='*.CCF' --exclude='*/' sasdev-xmm.esac.esa.int::XMM_VALID_CCF xmm-ccf
            fi

      # We also download the Chandra CalDB
      - run:
          name: Acquiring/validating Chandra CalDB
          command: |
            # If the chandra-caldb directory doesn't exist, or it does but the version file doesn't contain the
            #  same version number as currently defined in the environment variable, we have to download the data
            if [ ! -d chandra-caldb ] || [[ ! "$(<"chandra-caldb/chandra-caldb.ver")" == "$CHANDRA_CALDB_VER" ]]; then
              # Make a directory and version file (this helps avoid CircleCI's restrictions on
              #  dynamical cache key/path names) - delete an existing directory if it exists
              [ -d chandra-caldb ] && rm -rf chandra-caldb
              mkdir -p chandra-caldb

              echo "${CHANDRA_CALDB_VER}" > chandra-caldb/chandra-caldb.ver

              # Download the Chandra CalDB
              wget https://cxc.cfa.harvard.edu/cdaftp/arcftp/caldb/caldb_${CHANDRA_CALDB_VER}_main.tar.gz
              # Unpack the archive into a specific directory
              tar xzf caldb_${CHANDRA_CALDB_VER}_main.tar.gz -C chandra-caldb
              rm caldb_${CHANDRA_CALDB_VER}_main.tar.gz
            fi

      # Now we're sure we've downloaded all the local calibration files we need, we need to make sure that
      #  the mission-specific software can find those files.
      # Normally you do this by setting certain environment variables, but in this case those variables will be
      #  set by conda environments loaded in during the build process - they would override anything we set here. As
      #  such, we will symlink the calibration files to where the Fornax-Hea environments expect them to be.
      - run:
          name: Setting up calibration files
          command: |
            # On the Fornax system, the support data directory (which we use to store calibration files, amongst
            #  other things) is mounted from a different AWS system. In some versions of the Fornax-Hea images, that
            #  can leave a broken symlink that we want to remove and replace with a real directory that we can
            #  link our calibration files into.
            # This step may become unnecessary, with some changes to the Fornax-Hea image that are still in dev, but
            #  until then we're going:
            #   Check if there is a broken symlink
            #   If there is, remove it and replace it with a real directory
            [ -L "$SUPPORT_DATA_DIR" ] && ! [ -e "$SUPPORT_DATA_DIR" ] && rm "$SUPPORT_DATA_DIR"
            # Then make a new support data directory, if it didn't already exist
            mkdir -p $SUPPORT_DATA_DIR

            # Linking the XMM CCFs to the location expected by the Fornax-Hea SAS conda environment
            ln -s ~/xmm-ccf $SUPPORT_DATA_DIR/xmm_ccf

            # Linking the Chandra CalDB
            ln -s ~/chandra-caldb $SUPPORT_DATA_DIR/ciao-caldb-${CHANDRA_CALDB_VER}


      # TODO REMOVE THIS WHEN FORNAX-HEA CAN BE USED AS INTENDED
      - run:
          name: Force re-install of HEASoft
          command: |
            rm -rf /opt/envs/heasoft/heasoft
            micromamba install -y -c https://heasarc.gsfc.nasa.gov/FTP/software/conda/ -c conda-forge -n heasoft --force-reinstall heasoft

      - run:
          name: Installing extra dependencies
          # TODO THIS METHOD OF DEFINING DEPS IS NOT GOOD ENOUGH, EVEN FOR A TEMPORARY SOLUTION
          command: |
            micromamba install -y -c conda-forge -n heasoft astroquery pyvo tqdm aplpy s3fs

      - run:
          name: Create the build environment
          command: |
            micromamba create -n build_docs -y -c conda-forge sphinx sphinx-book-theme sphinx-copybutton myst-nb

      # To ensure that the build environment can activate the HEASoft, CIAO, etc. kernels when required
      - run:
          name: Add Fornax-hea kernels to build environment
          command: |
            find /opt/jupyter/share/jupyter/kernels -maxdepth 1 -type d ! -name 'python3' -exec ln -s {} /opt/envs/build_docs/share/jupyter/kernels/ \;

      # Now we're going to start building the documentation
      - run:
          name: Build HTML rendering of notebooks
          no_output_timeout: 30m
          command: |
            micromamba run -n build_docs sphinx-build -b html . _build/html -nT --keep-going
            sed -E -i.bak '/caption-text/{N; s/.+caption-text.+\n<ul>/<ul>/; P;D;}' _build/html/index.html
            bash -c 'rm _build/html/index.html.bak'

      # The MySTNB build cache, so we can hopefully avoid re-executing notebooks unnecessarily
      - save_cache:
          key: jupyter_ch-{{ .Branch }}-{{epoch}}
          paths:
            - _build/.jupyter_cache

      # Cache the XMM CCFs so we don't have to download them every time - we checksum the version file
      #  we generated because CircleCI doesn't allow you to use environment variables in cache keys. This
      #  is a good way round that
      # (https://devops.stackexchange.com/questions/9147/how-to-get-other-than-no-value-when-interpolating-environment-some-var)
      - save_cache:
          key: xmm-ccf-cs{{ checksum "xmm-ccf/xmm-ccf.ver" }}
          paths:
            - xmm-ccf

      # Same deal with Chandra CalDB
      - save_cache:
          key: ciao-caldb-cs{{ checksum "chandra-caldb/chandra-caldb.ver" }}
          paths:
            - chandra-caldb

      - store_artifacts:
          path: _build/html

      - persist_to_workspace:
          root: _build
          paths:
            - html

workflows:
  build-for-PR:
    jobs:
      - pr-build-docs
