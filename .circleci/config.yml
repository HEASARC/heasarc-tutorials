version: 2.1

parameters:
  notebooks_to_build:
    type: string
    default: ""

jobs:
  pr-build-docs:
    # Allows parameters to be passed into the job when
    #  it is triggered through the API.
    # The notebooks to build parameter will be a comma-separated list of relative
    #  notebook paths to files that should be built. Every other notebook will be
    #  ignored. Default value of "" means that all notebooks will be built.
    parameters:
      notebooks_to_build:
        type: string
        default: ""
    # We're using a docker container as a run environment - particularly the NASA Fornax
    #  high-energy image that we maintain as part of the Fornax initiative
    docker:
      # The Fornax-Hea images can definitely be used here, just we're having some issues with what supporting files
      #  software are included at the moment, so it is easier to use a different image and just install HEASoft
      #  at the moment
      - image: ghcr.io/nasa-fornax/fornax-images/fornax-hea:20251030_1555
    # This sets the amount of compute that we'll use to run the on-PR builds/tests - this particular setup corresponds
    #  to 2 CPUs and 4GB of RAM as of 16th September 2025
    resource_class: medium
    # Setting up environment variables - for instance, the version of the Chandra CalDB we want to use
    environment:
      CHANDRA_CALDB_VER: 4.12.2
      CIRCLECI_XMM_CCF_VER: 1

    # What this job is actually going to do!
    steps:
      - attach_workspace:
          at: ~/

      # Checking out the branch we're interested in
      - checkout

      # 1. Load the most recent cache that matches the stub of the MyST notebook cache key
      # 2. Restore the XMM calibration file cache, saves us downloading it every time!
      # 3. And the same thing with the Chandra CalDB cache
      - restore_cache:
          name: Restoring MyST notebook cache
          # If there isn't a cache for this branch, we'll try and find the most recent cache.
          #  TODO Possibly would be best to use main branch, but currently main branch isn't built on here
          keys:
            - jupyter_ch-{{ .Branch }}-
            - jupyter_ch-
      - restore_cache:
          name: Restoring XMM CCF cache
          keys:
            - xmm-ccf-
      - restore_cache:
          name: Restoring Chandra CalDB cache
          keys:
            - ciao-caldb-

      # Some missions (e.g. XMM, Chandra, eROSITA) require that their calibration files are available locally. We
      #  don't want to download them every single time, so we're going to cache them for future runs.
      - run:
          name: Acquiring/validating XMM-CCFs
          no_output_timeout: 30m
          command: |
            # If we can't see the xmm_ccf directory, or the version file we generate doesn't contain the same
            #  version number as currently defined in the environment variable, we have to download the data
            if [ ! -d /home/jovyan/xmm-ccf ] || [[ ! "$(<"/home/jovyan/xmm-ccf/xmm-ccf.ver")" == "$CIRCLECI_XMM_CCF_VER" ]]; then

              # Makes the xmm-ccf directory, if it doesn't already exist. This is a different approach to the
              #  what we do for the Chandra CalDB below, as rsync will update files if there are newer versions
              #  available, so we don't want to delete the directory.
              mkdir -p /home/jovyan/xmm-ccf/ccf-files

              # We do delete the version file, if it exists, as if we get to this point then we are either downloading
              #  the data for the first time, or the version number has changed.
              [ -f /home/jovyan/xmm-ccf/xmm-ccf.ver ] && rm /home/jovyan/xmm-ccf/xmm-ccf.ver

              # Make a new version file - this goes a level up from the directory where the files will actually
              #  be stored (ccf-files), because the rsync process will delete the version file
              echo "${CIRCLECI_XMM_CCF_VER}" > /home/jovyan/xmm-ccf/xmm-ccf.ver

              # We don't include rsync in the Fornax-Hea image, so unfortunately we'll have to install it now. The
              #  neatest way is to make a new conda environment that just contains rsync
              micromamba create -n rsync-env -y -c conda-forge rsync

              # Actually rsync the calibration files
              micromamba run -n rsync-env rsync -v -a --delete --delete-after --force --include='*.CCF' --exclude='*/' sasdev-xmm.esac.esa.int::XMM_VALID_CCF /home/jovyan/xmm-ccf/ccf-files
            fi

      # Cache the XMM CCFs so we don't have to download them every time - we checksum the version file
      #  we generated because CircleCI doesn't allow you to use environment variables in cache keys. This
      #  is a good way round that
      # (https://devops.stackexchange.com/questions/9147/how-to-get-other-than-no-value-when-interpolating-environment-some-var)
      - save_cache:
          key: xmm-ccf-cs{{ checksum "/home/jovyan/xmm-ccf/xmm-ccf.ver" }}
          paths:
            - /home/jovyan/xmm-ccf

      # We also download the Chandra CalDB
      - run:
          name: Acquiring/validating Chandra CalDB
          no_output_timeout: 30m
          command: |
            # If the chandra-caldb directory doesn't exist, or it does but the version file doesn't contain the
            #  same version number as currently defined in the environment variable, or the version file doesn't
            #  exist at all, we have to download the data,
            if [ ! -d /home/jovyan/chandra-caldb ] || [ ! -f /home/jovyan/chandra-caldb/chandra-caldb.ver ] || [[ ! "$(<"/home/jovyan/chandra-caldb/chandra-caldb.ver")" == "$CHANDRA_CALDB_VER" ]]; then

              # Make a directory (this helps avoid CircleCI's restrictions on
              #  dynamical cache key/path names) - delete an existing directory if it exists
              [ -d /home/jovyan/chandra-caldb ] && rm -rf /home/jovyan/chandra-caldb
              mkdir -p /home/jovyan/chandra-caldb

              # Download the Chandra CalDB
              wget https://cxc.cfa.harvard.edu/cdaftp/arcftp/ChandraCalDB/tars/caldb_${CHANDRA_CALDB_VER}_main.tar.gz

              # Unpack the archive into a specific directory
              tar xzf caldb_${CHANDRA_CALDB_VER}_main.tar.gz -C /home/jovyan/chandra-caldb
              rm caldb_${CHANDRA_CALDB_VER}_main.tar.gz

              # Make a version file
              echo "${CHANDRA_CALDB_VER}" > /home/jovyan/chandra-caldb/chandra-caldb.ver
            fi

      # Also add the Chandra CalDB to the cache
      - save_cache:
          key: ciao-caldb-cs{{ checksum "/home/jovyan/chandra-caldb/chandra-caldb.ver" }}
          paths:
            - /home/jovyan/chandra-caldb

      # Now we're sure we've downloaded all the local calibration files we need, we need to make sure that
      #  the mission-specific software can find those files.
      # Normally you do this by setting certain environment variables, but in this case those variables will be
      #  set by conda environments loaded in during the build process - they would override anything we set here. As
      #  such, we will symlink the calibration files to where the Fornax-Hea environments expect them to be.
      - run:
          name: Setting up calibration files
          command: |
            # On the Fornax system, the support data directory (which we use to store calibration files, amongst
            #  other things) is mounted from a different AWS system. In some versions of the Fornax-Hea images, that
            #  can leave a broken symlink that we want to remove and replace with a real directory that we can
            #  link our calibration files into.

            # This step may become unnecessary, with some changes to the Fornax-Hea image that are still in dev, but
            #  until then we're going to:
            #   Check if there is a broken symlink
            #   If there is, remove it and replace it with a real directory
            [ -L "$SUPPORT_DATA_DIR" ] && ! [ -e "$SUPPORT_DATA_DIR" ] && rm "$SUPPORT_DATA_DIR"
            # Then make a new support data directory, if it didn't already exist
            mkdir -p $SUPPORT_DATA_DIR

            # Linking the XMM CCFs to the location expected by the Fornax-Hea SAS conda environment
            ln -s /home/jovyan/xmm-ccf/ccf-files $SUPPORT_DATA_DIR/xmm_ccf

            # Linking the Chandra CalDB
            ln -s /home/jovyan/chandra-caldb $SUPPORT_DATA_DIR/ciao-caldb-${CHANDRA_CALDB_VER}

      - run:
          name: Installing extra dependencies
          # TODO THIS METHOD OF DEFINING DEPS IS NOT GOOD ENOUGH, EVEN FOR A TEMPORARY SOLUTION
          command: |
            micromamba install -y -c conda-forge -n heasoft astroquery pyvo tqdm aplpy s3fs boto3
            micromamba run -n heasoft pip install xga
            micromamba install -y -c conda-forge -n sas astroquery pyvo tqdm aplpy s3fs boto3

      - run:
          name: Create the Sphinx build environment
          command: |
            micromamba create -n build_docs -y -c conda-forge sphinx sphinx-book-theme sphinx-copybutton myst-nb

      # To ensure that the build environment can activate the HEASoft, CIAO, etc. kernels when required
      - run:
          name: Add Fornax-hea kernels to build environment
          command: |
            find /opt/jupyter/share/jupyter/kernels -maxdepth 1 -type d ! -name 'python3' -exec ln -s {} /opt/envs/build_docs/share/jupyter/kernels/ \;

      # Now we're going to start building the documentation
      - run:
          name: Build HTML rendering of notebooks
          no_output_timeout: 30m
          command: |
            # The first command sets the HEASARC_NOTEBOOKS_TO_BUILD environment variable, which tells the build
            #  process which notebooks to build. It allows granular control over which notebooks are built
            #  for a given test build - the default value of "" will build all the notebooks.
            export HEASARC_NOTEBOOKS_TO_BUILD="<< parameters.notebooks_to_build >>"
            micromamba run -n build_docs sphinx-build -b html . _build/html -nWT --keep-going
            sed -E -i.bak '/caption-text/{N; s/.+caption-text.+\n<ul>/<ul>/; P;D;}' _build/html/index.html
            bash -c 'rm _build/html/index.html.bak'

      - run:
          name: Rearrange built HTML and executed notebooks for artifact storage
          when: always
          command: |
            # We have to set the HEASARC_NOTEBOOKS_TO_BUILD environment variable again
            export HEASARC_NOTEBOOKS_TO_BUILD="<< parameters.notebooks_to_build >>"

            # First make the directory that will contain the files we want to
            #  retain as artifacts - don't include a '-p' flag here, as I would
            #  like this to error if the directory already exists.
            mkdir artifacts

            # Move the built HTML into the artifacts directory
            mv _build/html artifacts/

            # Create a directory within 'artifacts' for the executed notebooks
            mkdir artifacts/executed_notebooks

            # Moving on to the executed notebooks, we only want to retain the ones
            #  that were executed, so we will have to loop through the entries in the
            #  'HEASARC_NOTEBOOKS_TO_BUILD' environment variable set in the built-HTML
            #  step above.
            # This splits the variable into an array, so we can loop through it.
            IFS=',' read -ra built_nb_arr \<<< "$HEASARC_NOTEBOOKS_TO_BUILD"

            # Speaking of, now we loop through the notebooks that were targeted for building and construct
            #  the paths to where their equivalent executed notebooks should be stored.
            for cur_nb in "${built_nb_arr[@]}"; do
              # Replace the '.md' suffix that should have been attached to the notebooks
              #  specified in the 'notebooks_to_build' parameter passed to this
              #  job with '.ipynb'. Those executed notebooks with all the outputs
              #  are our targets
              cur_nb="${cur_nb%.md}.ipynb"

              # Construct the relative path to the executed notebook we're looking
              #  for at the moment
              cur_exec_nb_path="_build/jupyter_execute/tutorials/${cur_nb}"

              # We also need just the relative path, without the filename, so that
              #  we can construct a corresponding set of directories in the place
              #  where the executed notebook will end up
              cur_exec_dir=$(dirname "$cur_nb")
              # Set up the final directory path
              final_exec_nb_dir="artifacts/executed_notebooks/${cur_exec_dir}"

              # If the executed notebook exists, make the final executed notebook directory, then move the notebook into it
              [ -f $cur_exec_nb_path ] && mkdir -p $final_exec_nb_dir && mv $cur_exec_nb_path $final_exec_nb_dir
            done

      # The MySTNB build cache, so we can hopefully avoid re-executing notebooks unnecessarily
      - save_cache:
          key: jupyter_ch-{{ .Branch }}-{{epoch}}
          paths:
            - _build/.jupyter_cache

      - store_artifacts:
          path: artifacts

#      - persist_to_workspace:
#          root: _build
#          paths:
#            - html

workflows:
  build-for-PR:
    jobs:
      - pr-build-docs:
          notebooks_to_build: << pipeline.parameters.notebooks_to_build >>
